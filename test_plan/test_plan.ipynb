{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"CSCI3100: Software Engineering\"\n",
    "subtitle: \"Test Plan of AIO - Course Planner\"\n",
    "author: \"\"\n",
    "institute: \"Department of Computer Science And Engineering, The Chinese University of Hong Kong\"\n",
    "date: \"23 Apr 2025\"\n",
    "date-format: long\n",
    "format:\n",
    "  pdf:\n",
    "    toc: true\n",
    "    number-sections: true\n",
    "    colorlinks: true\n",
    "    include-in-header: \n",
    "      text: |\n",
    "        \\usepackage{fancyhdr}\n",
    "        \\pagestyle{fancy}\n",
    "execute:\n",
    "  echo: true\n",
    "  warning: true\n",
    "  output: true\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Revision History\n",
    "\n",
    "|Version| Revised By| Revision Date| Comments|\n",
    "|-------|-----------|--------------|---------|\n",
    "|1.0    | Anson     | 23 Apr 2025  | Initial draft| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test Plan for Pokeman Game\n",
    "\n",
    "This is a test plan for **AIO - Course Planner**. The most important sections include:\n",
    "\n",
    "1. Scope and Objectives --- This part states what will be (and what not will be) included in the testing.\n",
    "2. Test Cases and Scenarios --- This part explains each test case and scenario, by providing a detailed breakdown of the scope, the testing procedures and pass/fail criteria.\n",
    "3. Team Roles and Responsibilities --- This part shows the assignment of specific duties and accountabilities to each team member.\n",
    "4. Testing Approach & Timeline and Schedule --- This part outlines the approach and schedule of the tests.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scope and Objectives\n",
    "This part defines the scope of test cases. By having a clear definition, it avoids multiple test cases overlapping on certain areas.\n",
    "\n",
    "### Scope:\n",
    "The test plan focuses on ensuring the functionality, performance, and user experience of the **AIO - Course Planner**. The following areas will be tested:\n",
    "\n",
    "- Core mechanics (e.g., Timetable planning, Study Plan planner, Viewing degree roadmap, Course commenting).\n",
    "- User interface (UI) and user experience (UX).\n",
    "- Account system (Login, Logout, Registration).\n",
    "- Email token verification module.\n",
    "- Save/load functionality (for Timetable and Study Plan).\n",
    "- Third-party integration to Google Calendar.\n",
    "\n",
    "### Out of Scope:\n",
    "- Some hard-to-test aspects of the software (please see Risk assessment and mitigation).\n",
    "\n",
    "### Objectives:\n",
    "- Verify that the system meets functional and non-functional requirements, and provides a bug-free experience.\n",
    "- Ensure the system is intuitive, and free of critical bugs.\n",
    "- Confirm that the system performs well under various conditions (e.g., high user load, low-end devices). (????)\n",
    "- Validate that the system is ready for release and meets quality standards.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Cases and Scenarios\n",
    "The section outlines comprehensive testing strategies for the **AIO - Course Planner** web application. It has test cases for both functional and non-functional test scenarios designed to ensure the application meets quality standards and user requirements. Each test case includes procedures, expected results, and criteria to guide manual testing efforts into the testing process.\n",
    "\n",
    "The test cases below use manual testing steps currently, which can serve as the foundation for future test automation efforts.\n",
    "\n",
    "### Test Cases for Functional Requirements:\n",
    "1. User Authentication:\n",
    "   - Steps: Register a new account, verify email, and login with credentials.\n",
    "   - Expected Result: User is registered successfully and can log in without email verification (it is required for course commenting only).\n",
    "   - Pass/Fail Criteria: Account is not created in database or users cannot log in.\n",
    "   - Test cases: (TODO: DELETE THIS? NO AUTOMATED TESTING IS AVAILABLE)\n",
    "     - Test Case ID: TC001\n",
    "       - Repository Link: [GitHub - Test Code for TC001](https://github.com/project/repository/path/to/test_code_TC001)\n",
    "     - Test Case ID: TC002\n",
    "       - Repository Link: [GitHub - Test Code for TC002](https://github.com/project/repository/path/to/test_code_TC002)\n",
    "\n",
    "2. Course Search and Selection:\n",
    "   - Steps: Search for courses by keyword, filter results, and view course details.\n",
    "   - Expected Result: Relevant courses are displayed and details are accessible.\n",
    "   - Pass/Fail Criteria: Course search returns accurate results and course information is complete.\n",
    "\n",
    "3. Study Plan Creation:\n",
    "   - Steps: Add courses to study plan, modify sequence, and save changes.\n",
    "   - Expected Result: Study plan is updated and persisted correctly.\n",
    "   - Pass/Fail Criteria: Changes to study plan are saved and retrieved accurately on reload.\n",
    "\n",
    "4. Timetable Management:\n",
    "   - Steps: Add courses to timetable, detect conflicts, and optimize schedule.\n",
    "   - Expected Result: Courses appear in timetable at correct times with conflict warnings.\n",
    "   - Pass/Fail Criteria: Timetable visually displays all courses without UI errors.\n",
    "\n",
    "5. Comment System:\n",
    "   - Steps: Add comments to courses, edit/delete own comments, and view others' comments.\n",
    "   - Expected Result: Comments are saved and displayed correctly for all users.\n",
    "   - Pass/Fail Criteria: Comment operations complete without errors and update in real-time.\n",
    "\n",
    "6. Degree Roadmap Visualization:\n",
    "   - Steps: View degree roadmap, interact with course nodes, and check prerequisites.\n",
    "   - Expected Result: Roadmap displays correct course sequence with prerequisites highlighted.\n",
    "   - Pass/Fail Criteria: All course relationships are accurately represented in the visualization.\n",
    "\n",
    "\n",
    "### Test Cases for Non-Functional Requirements\n",
    "\n",
    "This part focus on test cases that assess the non-functional requirements focus on the quality attributes of the performance, scalability, usability, reliability, and security.\n",
    "\n",
    "#### 1. Performance Testing\n",
    "\n",
    "1. Page Load Time\n",
    "   - Objective: Verify that pages load within acceptable time limits.\n",
    "   - Steps:\n",
    "      1. Navigate to each main page (index, timetable, study planner, etc.)\n",
    "      2. Measure the time taken to fully load content.\n",
    "   - Expected Result: Pages load within 2 seconds on standard connections.\n",
    "   - Pass/Fail Criteria: Pass if load time meets expectations; fail otherwise.\n",
    "\n",
    "2. API Response Time\n",
    "   - Objective: Ensure API endpoints respond quickly to client requests.\n",
    "   - Steps:\n",
    "      1. Make requests to key API endpoints (course search, authentication, etc.)\n",
    "      2. Measure response times under different load conditions.\n",
    "   - Expected Result: API responses return within 500ms on average.\n",
    "   - Pass/Fail Criteria: Pass if response times remain within acceptable thresholds.\n",
    "\n",
    "3. Simultaneous User Testing\n",
    "   - Objective: Test application behavior with many concurrent users.\n",
    "   - Steps:\n",
    "      1. Simulate multiple users accessing the application simultaneously.\n",
    "      2. Monitor server resource usage and response times.\n",
    "   - Expected Result: Application remains responsive with up to 100 simultaneous users.\n",
    "   - Pass/Fail Criteria: Pass if performance degradation is minimal under load.\n",
    "\n",
    "\n",
    "#### 2. Usability Testing\n",
    "\n",
    "1. Navigation Flow\n",
    "   - Objective: Verify that users can navigate the application intuitively.\n",
    "   - Steps:\n",
    "      1. Ask new users to complete common tasks without instructions.\n",
    "      2. Observe navigation patterns and points of confusion.\n",
    "   - Expected Result: Users can complete basic tasks without assistance.\n",
    "   - Pass/Fail Criteria: Pass if users accomplish tasks efficiently; fail if significant confusion occurs.\n",
    "\n",
    "2. Mobile Responsiveness\n",
    "   - Objective: Ensure the application is usable on mobile devices.\n",
    "   - Steps:\n",
    "      1. Access application on various mobile devices and screen sizes.\n",
    "      2. Test all major features on mobile browsers.\n",
    "   - Expected Result: UI adapts appropriately to screen size with all functionality accessible.\n",
    "   - Pass/Fail Criteria: Pass if mobile experience is consistent with desktop.\n",
    "\n",
    "#### 3. Reliability Testing\n",
    "\n",
    "1. Data Persistence\n",
    "   - Objective: Verify that user data is saved correctly and persistently.\n",
    "   - Steps:\n",
    "      1. Create study plans and timetables, then log out and back in.\n",
    "      2. Check that all user-created data is preserved.\n",
    "   - Expected Result: All user data is persistent across sessions.\n",
    "   - Pass/Fail Criteria: Pass if no data loss occurs; fail otherwise.\n",
    "\n",
    "2. Error Recovery\n",
    "   - Objective: Test application's ability to handle and recover from errors.\n",
    "   - Steps:\n",
    "      1. Simulate network disruptions during operations.\n",
    "      2. Intentionally submit invalid data to test error handling.\n",
    "   - Expected Result: Application provides meaningful error messages and recovers gracefully.\n",
    "   - Pass/Fail Criteria: Pass if app maintains usability after errors.\n",
    "\n",
    "\n",
    "#### 4. Security Testing\n",
    "\n",
    "1. Authentication Security\n",
    "   - Objective: Verify secure login and session management.\n",
    "   - Steps:\n",
    "      1. Attempt various authentication bypass techniques.\n",
    "      2. Test password strength requirements and account lockout functionality.\n",
    "   - Expected Result: Unauthorized access attempts are prevented.\n",
    "   - Pass/Fail Criteria: Pass if authentication barriers cannot be circumvented.\n",
    "\n",
    "2. Data Protection\n",
    "   - Objective: Ensure user data is protected.\n",
    "   - Steps:\n",
    "      1. Inspect network traffic for sensitive data transmission.\n",
    "      2. Test that API endpoints properly validate authentication.\n",
    "   - Expected Result: Sensitive data is encrypted and access-controlled.\n",
    "   - Pass/Fail Criteria: Pass if no unauthorized data access is possible.\n",
    "\n",
    "#### 5. Compatibility Testing\n",
    "\n",
    "1. Browser Compatibility\n",
    "   - Objective: Ensure functionality across major browsers.\n",
    "   - Steps:\n",
    "      1. Test application on Chrome, Firefox, Safari, and Edge.\n",
    "      2. Verify feature parity and visual consistency.\n",
    "   - Expected Result: Application works identically across all supported browsers.\n",
    "   - Pass/Fail Criteria: Pass if no browser-specific issues exist.\n",
    "\n",
    "2. Device Compatibility\n",
    "   - Objective: Verify application works on different devices and screen sizes.\n",
    "   - Steps:\n",
    "      1. Test on desktop, tablet, and mobile devices.\n",
    "      2. Check for layout or functionality issues.\n",
    "   - Expected Result: Application is fully functional across all device types.\n",
    "   - Pass/Fail Criteria: Pass if the experience is consistent across devices.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resource Allocation\n",
    "This section outlines the personnel, tools, environments and other resources required to execute the test plan effectively.\n",
    "\n",
    "### 1. Team Roles and Responsibilities\n",
    "\n",
    "#### Key Team Members: (TODO: Fix this part cuz we just share the work...)\n",
    "1. Test Lead:\n",
    "    - Oversees the entire testing process.\n",
    "    - Creates test plans. \n",
    "    - Reports progress to stakeholders.\n",
    "2. Manual Testers (2-3):\n",
    "    - Execute functional and non-functional test cases.\n",
    "    - Document results. \n",
    "    - Report bugs.\n",
    "3. Frontend Developer:\n",
    "    - Assists with UI/UX testing. \n",
    "    - Resolves front-end related issues.\n",
    "4. Backend Developer:\n",
    "    - Assists with API testing. \n",
    "    - Resolves server-side issues.\n",
    "5. Database Administrator:\n",
    "    - Manages database configurations.\n",
    "\n",
    "#### Resource Allocation Table: (TODO: Fix this)\n",
    "\n",
    "| Team Member | Primary Testing Focus | Secondary Focus | Contribution (%) |\n",
    "|-------------|----------------------|-----------------|------------------|\n",
    "| Group Leader | Test planning, coordination | UI/UX testing | 25% |\n",
    "| Team Member 1 | Authentication & user management | Performance testing | 25% |\n",
    "| Team Member 2 | Course search & management | Browser compatibility | 25% |\n",
    "| Team Member 3 | Timetable & study planner features | Security testing | 25% |\n",
    "\n",
    "\n",
    "### 2. Tools and Software\n",
    "\n",
    "#### Testing Tools:\n",
    "- Browser Developer Tools: Chrome DevTools for frontend testing.\n",
    "- MongoDB Compass: For database inspection and verification.\n",
    "- Manual Testing: Since no framework is used for webapp building.\n",
    "- Git: For version controlling test scripts/datasets/files and documents.\n",
    "\n",
    "### 3. Testing Environments\n",
    "\n",
    "#### Environment Types:\n",
    "- Virtual Machine (Docker): Both developing, testing and production environments are containerized by Docker to avoid endpoint discrepency.\n",
    "- Developing environment: Consists of test files and source codes, used by developers for developing, testing and debugging.\n",
    "- Production Environment: Used for final validation during User Acceptance Testing. Mimics the live environment to ensure the system is ready for release.\n",
    "\n",
    "#### Environment Setup:\n",
    "- Hardware Requirements:\n",
    "    - Devices/Browsers/DevTool mimicing to test behaviour of the web-application in different devices.\n",
    "\n",
    "- Software Requirements:\n",
    "    - Docker (Compose) Containers: For consistent testing environments.\n",
    "    - Node.js: The backend of the web-application.\n",
    "    - MongoDB Database: Stores user data and comments.\n",
    "\n",
    "#### Environment Allocation Table: (TODO: Fix this)\n",
    "\n",
    "| Environment | Purpose | Configuration | Responsibility |\n",
    "|-------------|---------|--------------|----------------|\n",
    "| Local | Individual feature testing | Local installations on each member's computer | Individual Team Members |\n",
    "| Shared Test | Coordinated testing | Docker compose setup accessible to all members | Group Leader + Team Member with Docker knowledge |\n",
    "| Production-like | Final validation | Deployment to free tier hosting (if available) | Group Leader |\n",
    "\n",
    "\n",
    "### 4. Time Allocation\n",
    "\n",
    "#### Effort Estimation: (TODO: Fix this later)\n",
    "\n",
    "- Effort Estimation:\n",
    "        1. Test Planning: 3-4 days\n",
    "        2. Test Case Development: 1 week\n",
    "        3. Functional Testing: 1-2 weeks\n",
    "        4. Non-functional Testing: 1 week\n",
    "        5. Bug Fixing and Verification: Ongoing throughout project\n",
    "\n",
    "#### Example Time Allocation Table: (TODO: Fix this later)\n",
    "\n",
    "| Testing Phase | Duration | Team Members Involved | Deliverables |\n",
    "|---------------|----------|----------------------|--------------|\n",
    "| Test Planning | 3-4 days | All team members, led by Group Leader | Test Plan Document |\n",
    "| Test Case Development | 1 week | All team members | Test Cases, Test Data |\n",
    "| Authentication Testing | 2-3 days | Team Member 1, supported by others | Test Results, Bug Reports |\n",
    "| Course Management Testing | 2-3 days | Team Member 2, supported by others | Test Results, Bug Reports |\n",
    "| Study Plan & Timetable Testing | 3-4 days | Team Member 3, supported by others | Test Results, Bug Reports |\n",
    "| UI/UX Testing | 2-3 days | Group Leader, supported by others | Test Results, Bug Reports |\n",
    "| Performance & Security Testing | 2-3 days | Shared responsibility | Performance Report |\n",
    "| Compatibility Testing | 1-2 days | Team Member 2, supported by others | Compatibility Report |\n",
    "| Bug Fixing & Verification | Ongoing | All team members | Updated Application |\n",
    "\n",
    "### 5. Budget Allocation\n",
    "\n",
    "#### Key Budget Considerations:\n",
    "- Time Investment: Primary resource is team members' time.\n",
    "- Free Tools: Utilizing free versions instead of premium versions of software/services.\n",
    "- Personal Computing Resources: Using team members' own computers.\n",
    "- Cloud Resources: Minimal use of free tier cloud services if needed (e.g. using `EtherealMail` + `NodeMailer` to mimic email sending).\n",
    "- No Monetary Budget: Focus on free resources and time allocation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing Approach\n",
    "\n",
    "### Types of Testing:\n",
    "\n",
    "\n",
    "### Methodologies:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Timeline and Schedule\n",
    "\n",
    "### 1. Waterfall Model (THIS CHANGE)\n",
    "\n",
    "#### Dependencies:\n",
    "\n",
    "\n",
    "#### Key Phases and Timeline:\n",
    "\n",
    "#### Waterfall Model Timeline Example:\n",
    "\n",
    "\n",
    "\n",
    "### 2. Agile Model\n",
    "\n",
    "#### Key Phases and Timeline:\n",
    "\n",
    "#### Agile Model Timeline Example for a 2-Week Sprint:\n",
    "\n",
    "#### Agile Model Key Milestones:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Risk Assessment and Mitigation\n",
    "\n",
    "### Potential Risks:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Success Criteria\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Reporting Requirements\n",
    "\n",
    "### Documentation:\n",
    "\n",
    "### Communication:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
